{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание. Реализация логистической регрессии в TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерируем данные для задачи регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 2\n",
    "NUM_SAMPLES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples = NUM_SAMPLES,\n",
    "                           n_features = NUM_FEATURES,\n",
    "                           n_informative = NUM_FEATURES,\n",
    "                           n_redundant = 0,\n",
    "                           n_classes = 2,\n",
    "                           n_clusters_per_class = 1,\n",
    "                           class_sep = 0.75,\n",
    "                           random_state = 54312)\n",
    "\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "ones = np.where(y == 1)   # индексы объектов класса '1'\n",
    "zeros = np.where(y == 0)  # индексы объектов класса '0'\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.plot(X[ones, 0], X[ones, 1], 'ob',\n",
    "         X[zeros, 0], X[zeros, 1], 'or');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вспомогательная функция для создания операций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def py_func_with_grad(func, inp, Tout, grad, name = None, stateful = False, graph = None):\n",
    "    \n",
    "    name_prefix = ''.join(np.random.choice(list(string.ascii_letters), size = 10))\n",
    "    \n",
    "    name = '%s_%s' % (name_prefix, name or '')\n",
    "    grad_func_name = '%s_grad' % name\n",
    "\n",
    "    tf.RegisterGradient(grad_func_name)(grad)\n",
    "\n",
    "    g = graph or tf.get_default_graph()\n",
    "    with g.gradient_override_map({'PyFunc': grad_func_name, \n",
    "                                  'PyFuncStateless': grad_func_name}):\n",
    "        with tf.name_scope(name, 'PyFuncOp', inp):\n",
    "            return tf.py_func(func, inp, Tout, stateful = stateful, name = name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация линейной опреаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_op_forward(X, W):\n",
    "    ''' Реализация линейной операции '''\n",
    "    return np.dot(X, W.T)  # аргументы являются numpy-массивами\n",
    "\n",
    "def linear_op_backward(op, grads):\n",
    "    ''' Реализация вычисления градиента линейной операции '''\n",
    "    X = op.inputs[0]  # тензор входных данных\n",
    "    W = op.inputs[1]  # тензор параметров модели\n",
    "    dX = tf.multiply(grads, W)\n",
    "    dW = tf.reduce_sum(tf.multiply(X, grads),\n",
    "                       axis = 0,\n",
    "                       keep_dims = True)\n",
    "    return dX, dW\n",
    "\n",
    "def sigmoid_op_forward(X):\n",
    "    # TODO: реализовать операцию sigmoid\n",
    "    return tf.sigmoid(X)\n",
    "\n",
    "def sigmoid_op_backward(op, grads):\n",
    "    X = op.inputs[0] # тензор входных данных\n",
    "    dX = tf.multiply(grads, tf.sigmoid(X)*(1 - tf.sigmoid(X)))\n",
    "    dW = tf.reduce_sum(tf.multiply(X, grads),\n",
    "                       axis = 0,\n",
    "                       keep_dims = True)\n",
    "    # TODO: реализовать вычисление градиента для sigmoid\n",
    "    return (dX, dW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание графа вычислений и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Num gradients 2 generated for op name: \"sKvbpTDhbX_sigmoid_op/sKvbpTDhbX_sigmoid_op\"\nop: \"PyFuncStateless\"\ninput: \"sKvbpTDhbX_sigmoid_op/sKvbpTDhbX_sigmoid_op/input_0\"\nattr {\n  key: \"Tin\"\n  value {\n    list {\n      type: DT_FLOAT\n    }\n  }\n}\nattr {\n  key: \"Tout\"\n  value {\n    list {\n      type: DT_FLOAT\n    }\n  }\n}\nattr {\n  key: \"_gradient_op_type\"\n  value {\n    s: \"sKvbpTDhbX_sigmoid_op_grad\"\n  }\n}\nattr {\n  key: \"token\"\n  value {\n    s: \"pyfunc_19\"\n  }\n}\n do not match num inputs 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-3c599b8fe83c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# инициализируем оптимизатор и указываем скорость обучения\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# инициализируем placeholder'ы и переменные\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         grad_loss=grad_loss)\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0mvars_with_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgate_gradients\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGATE_OP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         colocate_gradients_with_ops=colocate_gradients_with_ops)\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgate_gradients\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGATE_GRAPH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m       \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients)\u001b[0m\n\u001b[1;32m    628\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     return _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops,\n\u001b[0;32m--> 630\u001b[0;31m                             gate_gradients, aggregation_method, stop_gradients)\n\u001b[0m\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, src_graph)\u001b[0m\n\u001b[1;32m    819\u001b[0m                                          lambda: _SymGrad(op, out_grads))\n\u001b[1;32m    820\u001b[0m               \u001b[0min_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_AsList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m               \u001b[0m_VerifyGeneratedGradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m               if gate_gradients and len([x for x in in_grads\n\u001b[1;32m    823\u001b[0m                                          if x is not None]) > 1:\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_VerifyGeneratedGradients\u001b[0;34m(grads, op)\u001b[0m\n\u001b[1;32m    321\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     raise ValueError(\"Num gradients %d generated for op %s do not match num \"\n\u001b[0;32m--> 323\u001b[0;31m                      \"inputs %d\" % (len(grads), op.node_def, len(op.inputs)))\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Num gradients 2 generated for op name: \"sKvbpTDhbX_sigmoid_op/sKvbpTDhbX_sigmoid_op\"\nop: \"PyFuncStateless\"\ninput: \"sKvbpTDhbX_sigmoid_op/sKvbpTDhbX_sigmoid_op/input_0\"\nattr {\n  key: \"Tin\"\n  value {\n    list {\n      type: DT_FLOAT\n    }\n  }\n}\nattr {\n  key: \"Tout\"\n  value {\n    list {\n      type: DT_FLOAT\n    }\n  }\n}\nattr {\n  key: \"_gradient_op_type\"\n  value {\n    s: \"sKvbpTDhbX_sigmoid_op_grad\"\n  }\n}\nattr {\n  key: \"token\"\n  value {\n    s: \"pyfunc_19\"\n  }\n}\n do not match num inputs 1"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = NUM_SAMPLES // 10\n",
    "\n",
    "weights = None  # в этой переменной мы сохраним результат обучения модели\n",
    "learning_curve = []  # значения ошибки на каждой итерации обучения\n",
    "\n",
    "with tf.Session(graph = tf.Graph()) as sess:  # инициализируем сессию вычислений\n",
    "    \n",
    "    # создаем placeholdr'ы, через них мы будем\n",
    "    # передавать внешние данные в граф вычислений\n",
    "    plh_X = tf.placeholder(dtype = tf.float32, shape = [None, NUM_FEATURES])\n",
    "    plh_labels = tf.placeholder(dtype = tf.float32, shape = [None, 1])\n",
    "\n",
    "    # создаем переменную для хранения весов модели\n",
    "    # эти веса будут изменяться в процессе обучения\n",
    "    var_W = tf.Variable(tf.random_uniform(shape = [1, NUM_FEATURES],\n",
    "                                          dtype = tf.float32,\n",
    "                                          seed = 54321))\n",
    "    \n",
    "    # создаем переменную для результата предсказания модели\n",
    "    var_Pred = py_func_with_grad(linear_op_forward,         # функция предсказания модели \n",
    "                                 [plh_X, var_W],            # аргументы функции\n",
    "                                 [tf.float32],              # тип выходных значений\n",
    "                                 name = 'linear_op',        # имя операции \n",
    "                                 grad = linear_op_backward, # функция для вычисления градиента\n",
    "                                 graph = sess.graph)        # объект графа вчислений\n",
    "    \n",
    "    # создаем переменную для результата операции sigmoid\n",
    "    var_Sigmoid = py_func_with_grad(sigmoid_op_forward,\n",
    "                                    [var_Pred],\n",
    "                                    [tf.float32],\n",
    "                                    name = 'sigmoid_op',\n",
    "                                    grad = sigmoid_op_backward,\n",
    "                                    graph = sess.graph)\n",
    "    \n",
    "    # кроссэнтропийная функция потерь для бмнарной классификации\n",
    "    cost = tf.losses.sigmoid_cross_entropy(plh_labels, var_Sigmoid)\n",
    "    \n",
    "    # инициализируем оптимизатор и указываем скорость обучения\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.9).minimize(cost)\n",
    "\n",
    "    # инициализируем placeholder'ы и переменные\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    indices = np.arange(len(X))  # массив индексов объектов\n",
    "    \n",
    "    # выполняем итерации по 10-ти эпохам\n",
    "    for epoch in range(10):\n",
    "        \n",
    "        # вначале каждой эпохи перемешиваем индексы\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        # внутри каждой эпохи данные разбиваются на батчи\n",
    "        for batch in range(len(X) // BATCH_SIZE):\n",
    "            \n",
    "            # выбираем индексы очередного батча\n",
    "            batch_indices = indices[batch * BATCH_SIZE:(batch + 1) * BATCH_SIZE]\n",
    "\n",
    "            # выполняем шаг обучения: вычисляем ошибку и обновляем веса\n",
    "            loss, _ = sess.run([cost, optimizer],  # указываем, какие операции необходимо выполнить\n",
    "                               feed_dict = {plh_X: X[batch_indices],  # передаем входные данные для вычисления\n",
    "                                            plh_labels: y[batch_indices]})\n",
    "        \n",
    "            # сохраняем занчения ошибки для построения кривой обучения\n",
    "            learning_curve.append(loss)\n",
    "            \n",
    "            # выводим текущее значение ошибки для каждого 10го шага\n",
    "            steps = len(learning_curve) - 1\n",
    "            if steps % 10 == 0:\n",
    "                print('[%03d] loss=%.3f weights=%s' % (steps, loss, var_W.eval()))\n",
    "    \n",
    "    # сохраняем обученные веса\n",
    "    weights = var_W.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализируем кривую обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('step')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Learning curve')\n",
    "plt.plot(learning_curve);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализируем разделяющую гиперплоскость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = - X[:, 0] * weights[0, 0] / weights[0, 1]\n",
    "\n",
    "order = np.argsort(X[:, 0])\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.plot(X[ones, 0], X[ones, 1], 'ob',\n",
    "         X[zeros, 0], X[zeros, 1], 'or',\n",
    "         X[order, 0], y_pred[order], '-g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
